{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üèóÔ∏è HVAC AI Platform - One-Click Cloud Launcher\n",
    "\n",
    "**Repository:** `https://github.com/elliotttmiller/hvac.git`\n",
    "\n",
    "This notebook provides instant cloud deployment of the HVAC AI Platform on Google Colab.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Features\n",
    "- ‚úÖ Automated environment setup (Node.js 20+ LTS, Python 3.11+)\n",
    "- ‚úÖ Repository cloning and dependency installation\n",
    "- ‚úÖ Secure API key configuration (backend-style env names + preserved frontend VITE_ flags)\n",
    "- ‚úÖ Public URL tunneling (localtunnel / cloudflared) for frontend & backend\n",
    "- ‚úÖ Full platform launch via `start.py`\n",
    "\n",
    "---\n",
    "\n",
    "## üîê Required Secrets (what to provide)\n",
    "Provide one or more of the following secrets in Colab (Runtime ‚Üí Manage sessions ‚Üí Add secret) or enter them at prompt when running the cell below:\n",
    "\n",
    "- `AI_PROVIDER` ‚Äî provider name (e.g. `gemini`, `openai`, `anthropic`). Default: `gemini`.\n",
    "- `GEMINI_API_KEY` ‚Äî Google Gemini key (used by backend services).\n",
    "- `AI_API_KEY` ‚Äî Generic AI API key (fallback for non-Gemini providers).\n",
    "\n",
    "Notes:\n",
    "- The launcher will prefer the backend-style names (`AI_PROVIDER`, `GEMINI_API_KEY`, `AI_API_KEY`).\n",
    "- The generated `.env` will include backend variables and will preserve a small set of frontend `VITE_` flags (feature flags and client file limits) so the browser receives the expected runtime flags.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Quick Start\n",
    "1. **Run all cells sequentially** (Runtime ‚Üí Run all)\n",
    "2. **Enter your API keys** when prompted (the prompts use secure input)\n",
    "3. **Access your app** via the printed tunnel URLs\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## üîß Step 1: Mount Google Drive (Optional)\n",
    "\n",
    "Mount your Google Drive to persist data and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mount_drive",
    "outputId": "dcb75fd0-7ce8-48d0-b735-c961e6147a53"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully\")\n",
    "print(f\"üìÇ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## üêç Step 2: Verify Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_OwFIfJFkv_",
    "outputId": "b1ab40c7-9acf-4578-f54c-bb91426d224c"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install Node.js 20.x LTS from NodeSource\n",
    "echo \"üì¶ Installing Node.js 20.x LTS...\"\n",
    "\n",
    "# Check if Node.js is already installed\n",
    "if command -v node &> /dev/null; then\n",
    "    CURRENT_VERSION=$(node --version)\n",
    "    echo \"‚ÑπÔ∏è  Node.js already installed: $CURRENT_VERSION\"\n",
    "\n",
    "    # Check if version is 20+\n",
    "    MAJOR_VERSION=$(echo $CURRENT_VERSION | cut -d'v' -f2 | cut -d'.' -f1)\n",
    "    if [ \"$MAJOR_VERSION\" -ge 20 ]; then\n",
    "        echo \"‚úÖ Node.js version is sufficient (v20+)\"\n",
    "    else\n",
    "        echo \"‚ö†Ô∏è  Node.js version is too old, upgrading...\"\n",
    "        curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
    "        sudo apt-get install -y nodejs\n",
    "        echo \"‚úÖ Node.js upgraded successfully\"\n",
    "    fi\n",
    "else\n",
    "    echo \"‚ÑπÔ∏è  Node.js not found, installing...\"\n",
    "    curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
    "    sudo apt-get install -y nodejs\n",
    "    echo \"‚úÖ Node.js installed successfully\"\n",
    "fi\n",
    "\n",
    "# Verify installation\n",
    "echo \"‚úÖ Node.js version:\"\n",
    "node --version\n",
    "echo \"‚úÖ npm version:\"\n",
    "npm --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## üì• Step 4: Clone HVAC Repository\n",
    "\n",
    "Clone the repository from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "clone_repo",
    "outputId": "aa7f7103-d4e5-4083-d912-2f455658421c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define repo details\n",
    "REPO_URL = \"https://github.com/elliotttmiller/hvac.git\"\n",
    "REPO_DIR = \"/content/hvac\"\n",
    "\n",
    "# Remove existing directory if present\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f\"‚ö†Ô∏è  Removing existing directory: {REPO_DIR}\")\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "# Clone repository\n",
    "print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
    "!git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "print(f\"‚úÖ Repository cloned successfully\")\n",
    "print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Show directory contents\n",
    "print(\"\\nüìÅ Repository contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## üîê Step 5: Configure API Keys\n",
    "\n",
    "**CRITICAL:** Enter your API keys when prompted. These will be injected into `.env` file.\n",
    "\n",
    "You can get API keys from:\n",
    "- **Gemini:** https://makersuite.google.com/app/apikey\n",
    "- **OpenAI:** https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "configure_keys",
    "outputId": "82b43211-275f-46e9-ce7a-b18e3dab0d7c"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "print(\"üîê API Key Configuration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Match the repository's exact variable names (VITE_* keys) while allowing server-first fallbacks.\n",
    "# Priority: server-style names in userdata -> legacy VITE_ names in userdata -> interactive secure prompt.\n",
    "\n",
    "# Provider\n",
    "vite_ai_provider = (userdata.get('VITE_AI_PROVIDER') or userdata.get('AI_PROVIDER') or \"gemini\").strip()\n",
    "# Keys\n",
    "vite_ai_api_key = (userdata.get('VITE_AI_API_KEY') or userdata.get('AI_API_KEY') or \"\").strip()\n",
    "vite_gemini_api_key = (userdata.get('VITE_GEMINI_API_KEY') or userdata.get('GEMINI_API_KEY') or \"\").strip()\n",
    "\n",
    "# Model and generation params (use userdata if present, else fall back to repo defaults)\n",
    "vite_ai_model = (userdata.get('VITE_AI_MODEL') or \"gemini-2.5-flash\").strip()\n",
    "vite_ai_temperature = (userdata.get('VITE_AI_TEMPERATURE') or userdata.get('VITE_AI_TEMPERATURE') or \"0.1\").strip()\n",
    "vite_ai_max_tokens = (userdata.get('VITE_AI_MAX_TOKENS') or userdata.get('VITE_AI_MAX_TOKENS') or \"4096\").strip()\n",
    "\n",
    "# Feature flags (explicit set per repo)\n",
    "vite_feature_cache = (userdata.get('VITE_FEATURE_CACHE') or \"true\").strip()\n",
    "vite_feature_file_processing = (userdata.get('VITE_FEATURE_FILE_PROCESSING') or \"true\").strip()\n",
    "# Optional future flags - preserve commented defaults if not provided\n",
    "vite_feature_compliance = (userdata.get('VITE_FEATURE_COMPLIANCE') or \"\").strip()\n",
    "vite_feature_safety = (userdata.get('VITE_FEATURE_SAFETY') or \"\").strip()\n",
    "vite_feature_pricing = (userdata.get('VITE_FEATURE_PRICING') or \"\").strip()\n",
    "\n",
    "# Rate limiting\n",
    "vite_rate_limit_max_retries = (userdata.get('VITE_RATE_LIMIT_MAX_RETRIES') or \"3\").strip()\n",
    "vite_rate_limit_delay_ms = (userdata.get('VITE_RATE_LIMIT_DELAY_MS') or \"1000\").strip()\n",
    "vite_rate_limit_exponential_backoff = (userdata.get('VITE_RATE_LIMIT_EXPONENTIAL_BACKOFF') or \"true\").strip()\n",
    "\n",
    "# File processing (repo uses VITE_FILE_* names)\n",
    "vite_file_max_size = (userdata.get('VITE_FILE_MAX_SIZE') or \"10485760\").strip()\n",
    "vite_file_supported_formats = (userdata.get('VITE_FILE_SUPPORTED_FORMATS') or \"pdf,png,jpg,jpeg,dwg\").strip()\n",
    "vite_file_pdf_dpi = (userdata.get('VITE_FILE_PDF_DPI') or \"300\").strip()\n",
    "\n",
    "# Dev / HMR overrides (match .env.local)\n",
    "vite_port = (userdata.get('VITE_PORT') or \"3000\").strip()\n",
    "vite_hmr_client_port = (userdata.get('VITE_HMR_CLIENT_PORT') or \"3000\").strip()\n",
    "vite_allowed_hosts = (userdata.get('VITE_ALLOWED_HOSTS') or \"true\").strip()\n",
    "vite_cors = (userdata.get('VITE_CORS') or \"true\").strip()\n",
    "\n",
    "# If no API key found yet, prompt securely (legacy behavior preserved)\n",
    "if not (vite_ai_api_key or vite_gemini_api_key):\n",
    "    print(\"\\n‚ö†Ô∏è  No API key found in Colab secrets (VITE_AI_API_KEY / VITE_GEMINI_API_KEY / AI_API_KEY).\")\n",
    "    provider_prompt = input(\"\\nSelect AI Provider (gemini/openai/anthropic) [gemini]: \").strip().lower() or \"gemini\"\n",
    "    # keep provider aligned with repo name variable\n",
    "    vite_ai_provider = provider_prompt\n",
    "\n",
    "    if provider_prompt == \"gemini\":\n",
    "        vite_gemini_api_key = getpass(\"Enter your GEMINI API Key (input hidden): \").strip()\n",
    "    elif provider_prompt == \"openai\":\n",
    "        vite_ai_api_key = getpass(\"Enter your OPENAI API Key (input hidden): \").strip()\n",
    "    else:\n",
    "        vite_ai_api_key = getpass(\"Enter your API Key (input hidden): \").strip()\n",
    "\n",
    "# Normalize (remove stray newlines)\n",
    "vite_ai_provider = vite_ai_provider.replace(\"\\n\", \"\").strip()\n",
    "vite_ai_api_key = (vite_ai_api_key or \"\").replace(\"\\n\", \"\").strip()\n",
    "vite_gemini_api_key = (vite_gemini_api_key or \"\").replace(\"\\n\", \"\").strip()\n",
    "\n",
    "# Build .env content exactly matching the project's variable names and structure\n",
    "env_lines = [\n",
    "    \"# ============================================================================ \",\n",
    "    \"# AI Provider Configuration\",\n",
    "    \"# ============================================================================\",\n",
    "    \"\",\n",
    "    \"# AI Provider Selection\",\n",
    "    f\"VITE_AI_PROVIDER={vite_ai_provider}\",\n",
    "    \"\",\n",
    "    \"# AI API Key (use the appropriate key for your provider)\",\n",
    "    f\"VITE_AI_API_KEY={vite_ai_api_key}\",\n",
    "    \"#VITE_GEMINI_API_KEY=\" if not vite_gemini_api_key else f\"VITE_GEMINI_API_KEY={vite_gemini_api_key}\",\n",
    "    \"# VITE_OPENAI_API_KEY=your_openai_key_here\",\n",
    "    \"# VITE_ANTHROPIC_API_KEY=your_anthropic_key_here\",\n",
    "    \"\",\n",
    "    \"# Model Selection\",\n",
    "    f\"VITE_AI_MODEL={vite_ai_model}\",\n",
    "    \"\",\n",
    "    \"# AI Generation Parameters\",\n",
    "    f\"VITE_AI_TEMPERATURE={vite_ai_temperature}\",\n",
    "    f\"VITE_AI_MAX_TOKENS={vite_ai_max_tokens}\",\n",
    "    \"\",\n",
    "    \"# ============================================================================\",\n",
    "    \"# Feature Flags\",\n",
    "    \"# ============================================================================\",\n",
    "    \"\",\n",
    "    \"# Semantic Caching (default: true)\",\n",
    "    f\"VITE_FEATURE_CACHE={vite_feature_cache}\",\n",
    "    \"\",\n",
    "    \"# File Processing (default: true)\",\n",
    "    f\"VITE_FEATURE_FILE_PROCESSING={vite_feature_file_processing}\",\n",
    "    \"\",\n",
    "    \"# Future Features (default: false)\",\n",
    "    \"# VITE_FEATURE_COMPLIANCE=true\" if not vite_feature_compliance else f\"VITE_FEATURE_COMPLIANCE={vite_feature_compliance}\",\n",
    "    \"# VITE_FEATURE_SAFETY=true\" if not vite_feature_safety else f\"VITE_FEATURE_SAFETY={vite_feature_safety}\",\n",
    "    \"# VITE_FEATURE_PRICING=true\" if not vite_feature_pricing else f\"VITE_FEATURE_PRICING={vite_feature_pricing}\",\n",
    "    \"\",\n",
    "    \"# ============================================================================\",\n",
    "    \"# Rate Limiting\",\n",
    "    \"# ============================================================================\",\n",
    "    \"\",\n",
    "    f\"VITE_RATE_LIMIT_MAX_RETRIES={vite_rate_limit_max_retries}\",\n",
    "    f\"VITE_RATE_LIMIT_DELAY_MS={vite_rate_limit_delay_ms}\",\n",
    "    f\"VITE_RATE_LIMIT_EXPONENTIAL_BACKOFF={vite_rate_limit_exponential_backoff}\",\n",
    "    \"\",\n",
    "    \"# ============================================================================\",\n",
    "    \"# File Processing\",\n",
    "    \"# ============================================================================\",\n",
    "    \"\",\n",
    "    f\"VITE_FILE_MAX_SIZE={vite_file_max_size}\",\n",
    "    f\"VITE_FILE_SUPPORTED_FORMATS={vite_file_supported_formats}\",\n",
    "    f\"VITE_FILE_PDF_DPI={vite_file_pdf_dpi}\",\n",
    "    \"\",\n",
    "    \"# ---------------------------------------------------------------------------\",\n",
    "    \"# Dev server / HMR overrides (used by vite.config.ts)\",\n",
    "    \"# ---------------------------------------------------------------------------\",\n",
    "    \"# Vite dev server port (overrides default 3000)\",\n",
    "    f\"VITE_PORT={vite_port}\",\n",
    "    \"# HMR client port (useful when tunneling or using a proxy)\",\n",
    "    f\"VITE_HMR_CLIENT_PORT={vite_hmr_client_port}\",\n",
    "    \"# Controls allowed hosts handling (true or comma-separated hosts)\",\n",
    "    f\"VITE_ALLOWED_HOSTS={vite_allowed_hosts}\",\n",
    "    \"# Enable CORS for dev server (true/false)\",\n",
    "    f\"VITE_CORS={vite_cors}\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "env_content = \"\\n\".join(env_lines) + \"\\n\"\n",
    "\n",
    "# Write to /content/hvac/.env\n",
    "env_path = \"/content/hvac/.env\"\n",
    "os.makedirs(os.path.dirname(env_path), exist_ok=True)\n",
    "with open(env_path, \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"\\n‚úÖ .env file created successfully\")\n",
    "print(f\"üìÑ Location: {env_path}\")\n",
    "print(\"\\n‚ö†Ô∏è  API keys are sensitive - never commit .env to version control!\")\n",
    "\n",
    "# Redacted summary\n",
    "print(\"\\nüîé Summary:\")\n",
    "print(f\"  Provider: {vite_ai_provider}\")\n",
    "print(f\"  VITE_GEMINI_API_KEY present: {bool(vite_gemini_api_key)}\")\n",
    "print(f\"  VITE_AI_API_KEY present: {bool(vite_ai_api_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## üì¶ Step 6: Install Dependencies\n",
    "\n",
    "Install npm dependencies for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install_deps",
    "outputId": "195cb50e-13d2-4dda-83c7-4742ef4bb229"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /content/hvac\n",
    "\n",
    "echo \"üì¶ Installing npm dependencies...\"\n",
    "echo \"‚è±Ô∏è  This may take 2-3 minutes...\"\n",
    "\n",
    "npm install\n",
    "\n",
    "echo \"‚úÖ Dependencies installed successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## üöÄ Step 8: Launch Application\n",
    "\n",
    "**IMPORTANT:** This cell will start the application servers and create public URLs.\n",
    "\n",
    "The cell will:\n",
    "1. Run `start.py` to validate environment and start dev servers\n",
    "2. Create public tunnels for frontend (port 3000) and backend (port 4000)\n",
    "3. Print public URLs that you can access from any browser\n",
    "\n",
    "**Note:** The servers will keep running. To stop them, use Runtime ‚Üí Interrupt execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "launch_app",
    "outputId": "0868d8d9-a644-436b-f5cb-f4c7a192349b"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import socket\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "FRONTEND_PORT = 3000\n",
    "BACKEND_PORT = 4000\n",
    "PROJECT_ROOT = '/content/hvac'\n",
    "\n",
    "# ANSI Colors\n",
    "class Colors:\n",
    "    HEADER = '\\033[95m'\n",
    "    BLUE = '\\033[94m'\n",
    "    CYAN = '\\033[96m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "\n",
    "print(f\"{Colors.HEADER}üöÄ Initializing HVAC AI Platform (Cloudflare Edition)...{Colors.ENDC}\", flush=True)\n",
    "print(\"=\" * 70, flush=True)\n",
    "\n",
    "# 1. Install Cloudflare Tunnel (cloudflared)\n",
    "print(\"üì¶ Installing Cloudflare Tunnel...\", flush=True)\n",
    "if not os.path.exists(\"cloudflared\"):\n",
    "    subprocess.run(\n",
    "        [\"wget\", \"-q\", \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"],\n",
    "        check=True\n",
    "    )\n",
    "    subprocess.run([\"mv\", \"cloudflared-linux-amd64\", \"cloudflared\"], check=True)\n",
    "    subprocess.run([\"chmod\", \"+x\", \"cloudflared\"], check=True)\n",
    "    print(f\"{Colors.GREEN}‚úÖ cloudflared installed{Colors.ENDC}\", flush=True)\n",
    "else:\n",
    "    print(f\"{Colors.GREEN}‚úÖ cloudflared already present{Colors.ENDC}\", flush=True)\n",
    "\n",
    "# Ensure directory exists\n",
    "if not os.path.exists(PROJECT_ROOT):\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# 2. Cleanup Old Processes\n",
    "def kill_process_on_port(port):\n",
    "    try:\n",
    "        subprocess.run([\"fuser\", \"-k\", f\"{port}/tcp\"], capture_output=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"üîç Pre-flight check: Cleaning ports...\", flush=True)\n",
    "kill_process_on_port(FRONTEND_PORT)\n",
    "kill_process_on_port(BACKEND_PORT)\n",
    "\n",
    "# 3. Log Streamer\n",
    "def stream_logs(process, prefix, color):\n",
    "    try:\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            if line:\n",
    "                print(f\"{color}[{prefix}] {line.strip()}{Colors.ENDC}\", flush=True)\n",
    "    except (ValueError, OSError):\n",
    "        pass\n",
    "\n",
    "# 4. Run Diagnostics\n",
    "if os.path.exists('start.py'):\n",
    "    print(\"\\nü©∫ Running Platform Diagnostics...\", flush=True)\n",
    "    diag_proc = subprocess.run(['python3', 'start.py', '--no-dev'], capture_output=True, text=True)\n",
    "    if diag_proc.returncode != 0:\n",
    "        print(f\"{Colors.FAIL}‚ùå Diagnostics Failed:{Colors.ENDC}\", flush=True)\n",
    "        print(diag_proc.stdout, flush=True)\n",
    "    else:\n",
    "        print(f\"{Colors.GREEN}‚úÖ Environment Diagnostics Passed{Colors.ENDC}\", flush=True)\n",
    "\n",
    "# 5. Launch Servers\n",
    "print(f\"\\n{Colors.BOLD}‚ö° Launching Services...{Colors.ENDC}\", flush=True)\n",
    "\n",
    "env_vars = os.environ.copy()\n",
    "env_vars['FORCE_COLOR'] = 'true'\n",
    "\n",
    "frontend_proc = subprocess.Popen(['npm', 'run', 'dev'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True, env=env_vars)\n",
    "backend_proc = subprocess.Popen(['npm', 'run', 'dev:api'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True, env=env_vars)\n",
    "\n",
    "# Start Log Threads\n",
    "t_front = threading.Thread(target=stream_logs, args=(frontend_proc, \"Frontend\", Colors.CYAN))\n",
    "t_front.daemon = True; t_front.start()\n",
    "\n",
    "t_back = threading.Thread(target=stream_logs, args=(backend_proc, \"Backend \", Colors.BLUE))\n",
    "t_back.daemon = True; t_back.start()\n",
    "\n",
    "# 6. Wait for Ports\n",
    "def wait_for_port(port, timeout=60):\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            if sock.connect_ex((\"localhost\", port)) == 0:\n",
    "                return True\n",
    "        time.sleep(1)\n",
    "    return False\n",
    "\n",
    "print(\"‚è≥ Waiting for servers...\", flush=True)\n",
    "if wait_for_port(FRONTEND_PORT) and wait_for_port(BACKEND_PORT):\n",
    "    print(f\"{Colors.GREEN}‚úÖ Servers listening!{Colors.ENDC}\", flush=True)\n",
    "else:\n",
    "    print(f\"{Colors.FAIL}‚ùå Timeout waiting for servers.{Colors.ENDC}\", flush=True)\n",
    "\n",
    "# 7. Start Cloudflare Tunnels\n",
    "tunnel_urls = {}\n",
    "\n",
    "def start_cf_tunnel(port, name):\n",
    "    try:\n",
    "        # Start cloudflared\n",
    "        proc = subprocess.Popen(\n",
    "            [f\"{PROJECT_ROOT}/cloudflared\", \"tunnel\", \"--url\", f\"http://localhost:{port}\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "\n",
    "        # Parse output for the URL\n",
    "        for line in iter(proc.stdout.readline, ''):\n",
    "            if '.trycloudflare.com' in line:\n",
    "                # Extract URL using regex\n",
    "                match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
    "                if match:\n",
    "                    url = match.group(0)\n",
    "                    tunnel_urls[name] = url\n",
    "                    return # Stop reading once we have the URL\n",
    "    except Exception as e:\n",
    "        print(f\"Tunnel Error: {e}\")\n",
    "\n",
    "print(\"üåê Establishing Cloudflare Tunnels (No Password Required)...\", flush=True)\n",
    "t_cf_front = threading.Thread(target=start_cf_tunnel, args=(FRONTEND_PORT, 'Frontend'))\n",
    "t_cf_back = threading.Thread(target=start_cf_tunnel, args=(BACKEND_PORT, 'Backend'))\n",
    "\n",
    "t_cf_front.daemon = True; t_cf_front.start()\n",
    "t_cf_back.daemon = True; t_cf_back.start()\n",
    "\n",
    "# Wait for URLs to appear\n",
    "time.sleep(8)\n",
    "\n",
    "# 8. Final Dashboard\n",
    "print(\"\\n\" + \"=\" * 70, flush=True)\n",
    "print(f\"{Colors.GREEN}{Colors.BOLD}üéâ HVAC AI PLATFORM ONLINE{Colors.ENDC}\", flush=True)\n",
    "print(\"=\" * 70, flush=True)\n",
    "\n",
    "print(f\"{Colors.CYAN}üåç PUBLIC ACCESS (No Password Needed):{Colors.ENDC}\", flush=True)\n",
    "print(f\"   Frontend: {Colors.BOLD}{tunnel_urls.get('Frontend', 'Initializing...')}{Colors.ENDC}\", flush=True)\n",
    "print(f\"   Backend:  {Colors.BOLD}{tunnel_urls.get('Backend', 'Initializing...')}{Colors.ENDC}\", flush=True)\n",
    "print(\"\", flush=True)\n",
    "\n",
    "print(f\"{Colors.YELLOW}üè† LOCAL ACCESS:{Colors.ENDC}\", flush=True)\n",
    "print(f\"   Frontend: http://localhost:{FRONTEND_PORT}\", flush=True)\n",
    "print(\"-\" * 70, flush=True)\n",
    "print(f\"{Colors.BOLD}üìù LIVE SERVER LOGS:{Colors.ENDC}\", flush=True)\n",
    "print(\"-\" * 70, flush=True)\n",
    "\n",
    "# 9. Keep Alive\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        if frontend_proc.poll() is not None:\n",
    "            print(f\"{Colors.FAIL}‚ùå Frontend died{Colors.ENDC}\", flush=True); break\n",
    "        if backend_proc.poll() is not None:\n",
    "            print(f\"{Colors.FAIL}‚ùå Backend died{Colors.ENDC}\", flush=True); break\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüõë Shutting down...\", flush=True)\n",
    "    frontend_proc.terminate()\n",
    "    backend_proc.terminate()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
