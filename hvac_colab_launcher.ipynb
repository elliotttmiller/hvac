{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üèóÔ∏è HVAC AI Platform - One-Click Cloud Launcher\n",
        "\n",
        "**Repository:** `https://github.com/elliotttmiller/hvac.git`\n",
        "\n",
        "This notebook provides instant cloud deployment of the HVAC AI Platform on Google Colab.\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Features\n",
        "- ‚úÖ Automated environment setup (Node.js 20+ LTS, Python 3.11+)\n",
        "- ‚úÖ Repository cloning and dependency installation\n",
        "- ‚úÖ Secure API key configuration\n",
        "- ‚úÖ Public URL tunneling (localtunnel) for frontend & backend\n",
        "- ‚úÖ Full platform launch via `start.py`\n",
        "\n",
        "---\n",
        "\n",
        "## üîê Required Secrets\n",
        "Before running, you'll need:\n",
        "- `VITE_AI_API_KEY` or `VITE_GEMINI_API_KEY` - Your AI API key\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start\n",
        "1. **Run all cells sequentially** (Runtime ‚Üí Run all)\n",
        "2. **Enter your API keys** when prompted\n",
        "3. **Access your app** via the printed tunnel URLs\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "## üîß Step 1: Mount Google Drive (Optional)\n",
        "\n",
        "Mount your Google Drive to persist data and configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mount_drive",
        "outputId": "dcb75fd0-7ce8-48d0-b735-c961e6147a53"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted successfully\")\n",
        "print(f\"üìÇ Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## üêç Step 2: Verify Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_OwFIfJFkv_",
        "outputId": "b1ab40c7-9acf-4578-f54c-bb91426d224c"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Install Node.js 20.x LTS from NodeSource\n",
        "echo \"üì¶ Installing Node.js 20.x LTS...\"\n",
        "\n",
        "# Check if Node.js is already installed\n",
        "if command -v node &> /dev/null; then\n",
        "    CURRENT_VERSION=$(node --version)\n",
        "    echo \"‚ÑπÔ∏è  Node.js already installed: $CURRENT_VERSION\"\n",
        "\n",
        "    # Check if version is 20+\n",
        "    MAJOR_VERSION=$(echo $CURRENT_VERSION | cut -d'v' -f2 | cut -d'.' -f1)\n",
        "    if [ \"$MAJOR_VERSION\" -ge 20 ]; then\n",
        "        echo \"‚úÖ Node.js version is sufficient (v20+)\"\n",
        "    else\n",
        "        echo \"‚ö†Ô∏è  Node.js version is too old, upgrading...\"\n",
        "        curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "        sudo apt-get install -y nodejs\n",
        "        echo \"‚úÖ Node.js upgraded successfully\"\n",
        "    fi\n",
        "else\n",
        "    echo \"‚ÑπÔ∏è  Node.js not found, installing...\"\n",
        "    curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "    sudo apt-get install -y nodejs\n",
        "    echo \"‚úÖ Node.js installed successfully\"\n",
        "fi\n",
        "\n",
        "# Verify installation\n",
        "echo \"‚úÖ Node.js version:\"\n",
        "node --version\n",
        "echo \"‚úÖ npm version:\"\n",
        "npm --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## üì• Step 4: Clone HVAC Repository\n",
        "\n",
        "Clone the repository from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "clone_repo",
        "outputId": "aa7f7103-d4e5-4083-d912-2f455658421c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define repo details\n",
        "REPO_URL = \"https://github.com/elliotttmiller/hvac.git\"\n",
        "REPO_DIR = \"/content/hvac\"\n",
        "\n",
        "# Remove existing directory if present\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(f\"‚ö†Ô∏è  Removing existing directory: {REPO_DIR}\")\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "\n",
        "# Clone repository\n",
        "print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
        "!git clone {REPO_URL} {REPO_DIR}\n",
        "\n",
        "# Change to repo directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print(f\"‚úÖ Repository cloned successfully\")\n",
        "print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Show directory contents\n",
        "print(\"\\nüìÅ Repository contents:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## üîê Step 5: Configure API Keys\n",
        "\n",
        "**CRITICAL:** Enter your API keys when prompted. These will be injected into `.env` file.\n",
        "\n",
        "You can get API keys from:\n",
        "- **Gemini:** https://makersuite.google.com/app/apikey\n",
        "- **OpenAI:** https://platform.openai.com/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "configure_keys",
        "outputId": "82b43211-275f-46e9-ce7a-b18e3dab0d7c"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Attempt to load secrets using userdata.get\n",
        "print(\"üîê API Key Configuration\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Default to Colab secrets\n",
        "ai_provider = userdata.get('VITE_AI_PROVIDER') or \"gemini\"\n",
        "api_key = userdata.get('VITE_AI_API_KEY') or \"\"\n",
        "gemini_key = userdata.get('VITE_GEMINI_API_KEY') or \"\"\n",
        "\n",
        "# Fallback to manual input if keys are missing\n",
        "if not api_key:\n",
        "    print(\"\\n‚ö†Ô∏è  API key not found in Colab secrets. Falling back to manual input.\")\n",
        "    ai_provider = input(\"\\nSelect AI Provider (gemini/openai/anthropic) [gemini]: \").strip().lower() or \"gemini\"\n",
        "    if ai_provider == \"gemini\":\n",
        "        api_key = getpass(\"Enter your GEMINI API Key: \")\n",
        "        gemini_key = api_key\n",
        "    elif ai_provider == \"openai\":\n",
        "        api_key = getpass(\"Enter your OPENAI API Key: \")\n",
        "        gemini_key = \"\"\n",
        "    else:\n",
        "        api_key = getpass(\"Enter your API Key: \")\n",
        "        gemini_key = \"\"\n",
        "\n",
        "    # Optional: Gemini-specific key\n",
        "    if not gemini_key:\n",
        "        gemini_prompt = input(\"\\nAlso provide Gemini key? (y/n) [n]: \").strip().lower()\n",
        "        if gemini_prompt == 'y':\n",
        "            gemini_key = getpass(\"Enter your GEMINI API Key: \")\n",
        "\n",
        "# Generate .env file\n",
        "env_content = f\"\"\"# ============================================================================\n",
        "# AI Provider Configuration (Auto-generated by Colab Launcher)\n",
        "# ============================================================================\n",
        "\n",
        "# AI Provider Selection\n",
        "VITE_AI_PROVIDER={ai_provider}\n",
        "\n",
        "# AI API Key\n",
        "VITE_AI_API_KEY={api_key}\n",
        "\n",
        "# Provider-specific keys\n",
        "{f\"VITE_GEMINI_API_KEY={gemini_key}\" if gemini_key else \"# VITE_GEMINI_API_KEY=your_gemini_key_here\"}\n",
        "\n",
        "# Model Selection\n",
        "VITE_AI_MODEL={\"gemini-2.5-flash\" if ai_provider == \"gemini\" else \"gpt-4o\" if ai_provider == \"openai\" else \"claude-3-5-sonnet-20241022\"}\n",
        "\n",
        "# AI Generation Parameters\n",
        "VITE_AI_TEMPERATURE=0.2\n",
        "VITE_AI_MAX_TOKENS=4096\n",
        "\n",
        "# ============================================================================\n",
        "# Feature Flags\n",
        "# ============================================================================\n",
        "\n",
        "VITE_FEATURE_CACHE=true\n",
        "VITE_FEATURE_FILE_PROCESSING=true\n",
        "\n",
        "# ============================================================================\n",
        "# Rate Limiting\n",
        "# ============================================================================\n",
        "\n",
        "VITE_RATE_LIMIT_MAX_RETRIES=3\n",
        "VITE_RATE_LIMIT_DELAY_MS=1000\n",
        "VITE_RATE_LIMIT_EXPONENTIAL_BACKOFF=true\n",
        "\n",
        "# ============================================================================\n",
        "# File Processing\n",
        "# ============================================================================\n",
        "\n",
        "VITE_FILE_MAX_SIZE=10485760\n",
        "VITE_FILE_SUPPORTED_FORMATS=pdf,png,jpg,jpeg,dwg\n",
        "VITE_FILE_PDF_DPI=300\n",
        "\"\"\"\n",
        "\n",
        "# Write .env file\n",
        "env_path = \"/content/hvac/.env\"\n",
        "with open(env_path, \"w\") as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"\\n‚úÖ .env file created successfully\")\n",
        "print(f\"üìÑ Location: {env_path}\")\n",
        "print(\"\\n‚ö†Ô∏è  API keys are sensitive - never commit .env to version control!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6"
      },
      "source": [
        "## üì¶ Step 6: Install Dependencies\n",
        "\n",
        "Install npm dependencies for the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_deps",
        "outputId": "195cb50e-13d2-4dda-83c7-4742ef4bb229"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/hvac\n",
        "\n",
        "echo \"üì¶ Installing npm dependencies...\"\n",
        "echo \"‚è±Ô∏è  This may take 2-3 minutes...\"\n",
        "\n",
        "npm install\n",
        "\n",
        "echo \"‚úÖ Dependencies installed successfully\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step8"
      },
      "source": [
        "## üöÄ Step 8: Launch Application\n",
        "\n",
        "**IMPORTANT:** This cell will start the application servers and create public URLs.\n",
        "\n",
        "The cell will:\n",
        "1. Run `start.py` to validate environment and start dev servers\n",
        "2. Create public tunnels for frontend (port 3000) and backend (port 4000)\n",
        "3. Print public URLs that you can access from any browser\n",
        "\n",
        "**Note:** The servers will keep running. To stop them, use Runtime ‚Üí Interrupt execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "launch_app",
        "outputId": "0868d8d9-a644-436b-f5cb-f4c7a192349b"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import requests\n",
        "import socket\n",
        "import sys\n",
        "import re\n",
        "\n",
        "# Configuration\n",
        "FRONTEND_PORT = 3000\n",
        "BACKEND_PORT = 4000\n",
        "PROJECT_ROOT = '/content/hvac'\n",
        "\n",
        "# ANSI Colors\n",
        "class Colors:\n",
        "    HEADER = '\\033[95m'\n",
        "    BLUE = '\\033[94m'\n",
        "    CYAN = '\\033[96m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "\n",
        "print(f\"{Colors.HEADER}üöÄ Initializing HVAC AI Platform (Cloudflare Edition)...{Colors.ENDC}\", flush=True)\n",
        "print(\"=\" * 70, flush=True)\n",
        "\n",
        "# 1. Install Cloudflare Tunnel (cloudflared)\n",
        "print(\"üì¶ Installing Cloudflare Tunnel...\", flush=True)\n",
        "if not os.path.exists(\"cloudflared\"):\n",
        "    subprocess.run(\n",
        "        [\"wget\", \"-q\", \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"],\n",
        "        check=True\n",
        "    )\n",
        "    subprocess.run([\"mv\", \"cloudflared-linux-amd64\", \"cloudflared\"], check=True)\n",
        "    subprocess.run([\"chmod\", \"+x\", \"cloudflared\"], check=True)\n",
        "    print(f\"{Colors.GREEN}‚úÖ cloudflared installed{Colors.ENDC}\", flush=True)\n",
        "else:\n",
        "    print(f\"{Colors.GREEN}‚úÖ cloudflared already present{Colors.ENDC}\", flush=True)\n",
        "\n",
        "# Ensure directory exists\n",
        "if not os.path.exists(PROJECT_ROOT):\n",
        "    PROJECT_ROOT = os.getcwd()\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "# 2. Cleanup Old Processes\n",
        "def kill_process_on_port(port):\n",
        "    try:\n",
        "        subprocess.run([\"fuser\", \"-k\", f\"{port}/tcp\"], capture_output=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(\"üîç Pre-flight check: Cleaning ports...\", flush=True)\n",
        "kill_process_on_port(FRONTEND_PORT)\n",
        "kill_process_on_port(BACKEND_PORT)\n",
        "\n",
        "# 3. Log Streamer\n",
        "def stream_logs(process, prefix, color):\n",
        "    try:\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            if line:\n",
        "                print(f\"{color}[{prefix}] {line.strip()}{Colors.ENDC}\", flush=True)\n",
        "    except (ValueError, OSError):\n",
        "        pass\n",
        "\n",
        "# 4. Run Diagnostics\n",
        "if os.path.exists('start.py'):\n",
        "    print(\"\\nü©∫ Running Platform Diagnostics...\", flush=True)\n",
        "    diag_proc = subprocess.run(['python3', 'start.py', '--no-dev'], capture_output=True, text=True)\n",
        "    if diag_proc.returncode != 0:\n",
        "        print(f\"{Colors.FAIL}‚ùå Diagnostics Failed:{Colors.ENDC}\", flush=True)\n",
        "        print(diag_proc.stdout, flush=True)\n",
        "    else:\n",
        "        print(f\"{Colors.GREEN}‚úÖ Environment Diagnostics Passed{Colors.ENDC}\", flush=True)\n",
        "\n",
        "# 5. Launch Servers\n",
        "print(f\"\\n{Colors.BOLD}‚ö° Launching Services...{Colors.ENDC}\", flush=True)\n",
        "\n",
        "env_vars = os.environ.copy()\n",
        "env_vars['FORCE_COLOR'] = 'true'\n",
        "\n",
        "frontend_proc = subprocess.Popen(['npm', 'run', 'dev'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True, env=env_vars)\n",
        "backend_proc = subprocess.Popen(['npm', 'run', 'dev:api'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True, env=env_vars)\n",
        "\n",
        "# Start Log Threads\n",
        "t_front = threading.Thread(target=stream_logs, args=(frontend_proc, \"Frontend\", Colors.CYAN))\n",
        "t_front.daemon = True; t_front.start()\n",
        "\n",
        "t_back = threading.Thread(target=stream_logs, args=(backend_proc, \"Backend \", Colors.BLUE))\n",
        "t_back.daemon = True; t_back.start()\n",
        "\n",
        "# 6. Wait for Ports\n",
        "def wait_for_port(port, timeout=60):\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < timeout:\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            if sock.connect_ex((\"localhost\", port)) == 0:\n",
        "                return True\n",
        "        time.sleep(1)\n",
        "    return False\n",
        "\n",
        "print(\"‚è≥ Waiting for servers...\", flush=True)\n",
        "if wait_for_port(FRONTEND_PORT) and wait_for_port(BACKEND_PORT):\n",
        "    print(f\"{Colors.GREEN}‚úÖ Servers listening!{Colors.ENDC}\", flush=True)\n",
        "else:\n",
        "    print(f\"{Colors.FAIL}‚ùå Timeout waiting for servers.{Colors.ENDC}\", flush=True)\n",
        "\n",
        "# 7. Start Cloudflare Tunnels\n",
        "tunnel_urls = {}\n",
        "\n",
        "def start_cf_tunnel(port, name):\n",
        "    try:\n",
        "        # Start cloudflared\n",
        "        proc = subprocess.Popen(\n",
        "            [f\"{PROJECT_ROOT}/cloudflared\", \"tunnel\", \"--url\", f\"http://localhost:{port}\"],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Parse output for the URL\n",
        "        for line in iter(proc.stdout.readline, ''):\n",
        "            if '.trycloudflare.com' in line:\n",
        "                # Extract URL using regex\n",
        "                match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
        "                if match:\n",
        "                    url = match.group(0)\n",
        "                    tunnel_urls[name] = url\n",
        "                    return # Stop reading once we have the URL\n",
        "    except Exception as e:\n",
        "        print(f\"Tunnel Error: {e}\")\n",
        "\n",
        "print(\"üåê Establishing Cloudflare Tunnels (No Password Required)...\", flush=True)\n",
        "t_cf_front = threading.Thread(target=start_cf_tunnel, args=(FRONTEND_PORT, 'Frontend'))\n",
        "t_cf_back = threading.Thread(target=start_cf_tunnel, args=(BACKEND_PORT, 'Backend'))\n",
        "\n",
        "t_cf_front.daemon = True; t_cf_front.start()\n",
        "t_cf_back.daemon = True; t_cf_back.start()\n",
        "\n",
        "# Wait for URLs to appear\n",
        "time.sleep(8)\n",
        "\n",
        "# 8. Final Dashboard\n",
        "print(\"\\n\" + \"=\" * 70, flush=True)\n",
        "print(f\"{Colors.GREEN}{Colors.BOLD}üéâ HVAC AI PLATFORM ONLINE{Colors.ENDC}\", flush=True)\n",
        "print(\"=\" * 70, flush=True)\n",
        "\n",
        "print(f\"{Colors.CYAN}üåç PUBLIC ACCESS (No Password Needed):{Colors.ENDC}\", flush=True)\n",
        "print(f\"   Frontend: {Colors.BOLD}{tunnel_urls.get('Frontend', 'Initializing...')}{Colors.ENDC}\", flush=True)\n",
        "print(f\"   Backend:  {Colors.BOLD}{tunnel_urls.get('Backend', 'Initializing...')}{Colors.ENDC}\", flush=True)\n",
        "print(\"\", flush=True)\n",
        "\n",
        "print(f\"{Colors.YELLOW}üè† LOCAL ACCESS:{Colors.ENDC}\", flush=True)\n",
        "print(f\"   Frontend: http://localhost:{FRONTEND_PORT}\", flush=True)\n",
        "print(\"-\" * 70, flush=True)\n",
        "print(f\"{Colors.BOLD}üìù LIVE SERVER LOGS:{Colors.ENDC}\", flush=True)\n",
        "print(\"-\" * 70, flush=True)\n",
        "\n",
        "# 9. Keep Alive\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "        if frontend_proc.poll() is not None:\n",
        "            print(f\"{Colors.FAIL}‚ùå Frontend died{Colors.ENDC}\", flush=True); break\n",
        "        if backend_proc.poll() is not None:\n",
        "            print(f\"{Colors.FAIL}‚ùå Backend died{Colors.ENDC}\", flush=True); break\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Shutting down...\", flush=True)\n",
        "    frontend_proc.terminate()\n",
        "    backend_proc.terminate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
