{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üèóÔ∏è HVAC AI Platform - One-Click Cloud Launcher\n",
        "\n",
        "**Repository:** `https://github.com/elliotttmiller/hvac.git`\n",
        "\n",
        "This notebook provides instant cloud deployment of the HVAC AI Platform on Google Colab.\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Features\n",
        "- ‚úÖ Automated environment setup (Node.js 20+ LTS, Python 3.11+)\n",
        "- ‚úÖ Repository cloning and dependency installation\n",
        "- ‚úÖ Secure API key configuration\n",
        "- ‚úÖ Public URL tunneling (localtunnel) for frontend & backend\n",
        "- ‚úÖ Full platform launch via `start.py`\n",
        "\n",
        "---\n",
        "\n",
        "## üîê Required Secrets\n",
        "Before running, you'll need:\n",
        "- `VITE_AI_API_KEY` or `VITE_GEMINI_API_KEY` - Your AI API key\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start\n",
        "1. **Run all cells sequentially** (Runtime ‚Üí Run all)\n",
        "2. **Enter your API keys** when prompted\n",
        "3. **Access your app** via the printed tunnel URLs\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Step 1: Mount Google Drive (Optional)\n",
        "\n",
        "Mount your Google Drive to persist data and configurations."
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted successfully\")\n",
        "print(f\"üìÇ Current directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêç Step 2: Verify Environment\n",
        "\n",
        "Check Python version (should be 3.11+)"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Install Node.js 20.x LTS from NodeSource\n",
        "echo \"üì¶ Installing Node.js 20.x LTS...\"\n",
        "\n",
        "# Check if Node.js is already installed\n",
        "if command -v node &> /dev/null; then\n",
        "    CURRENT_VERSION=$(node --version)\n",
        "    echo \"‚ÑπÔ∏è  Node.js already installed: $CURRENT_VERSION\"\n",
        "\n",
        "    # Check if version is 20+\n",
        "    MAJOR_VERSION=$(echo $CURRENT_VERSION | cut -d'v' -f2 | cut -d'.' -f1)\n",
        "    if [ \"$MAJOR_VERSION\" -ge 20 ]; then\n",
        "        echo \"‚úÖ Node.js version is sufficient (v20+)\"\n",
        "    else\n",
        "        echo \"‚ö†Ô∏è  Node.js version is too old, upgrading...\"\n",
        "        curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "        sudo apt-get install -y nodejs\n",
        "        echo \"‚úÖ Node.js upgraded successfully\"\n",
        "    fi\n",
        "else\n",
        "    echo \"‚ÑπÔ∏è  Node.js not found, installing...\"\n",
        "    curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "    sudo apt-get install -y nodejs\n",
        "    echo \"‚úÖ Node.js installed successfully\"\n",
        "fi\n",
        "\n",
        "# Verify installation\n",
        "echo \"‚úÖ Node.js version:\"\n",
        "node --version\n",
        "echo \"‚úÖ npm version:\"\n",
        "npm --version"
      ],
      "metadata": {
        "id": "O_OwFIfJFkv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Step 4: Clone HVAC Repository\n",
        "\n",
        "Clone the repository from GitHub."
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define repo details\n",
        "REPO_URL = \"https://github.com/elliotttmiller/hvac.git\"\n",
        "REPO_DIR = \"/content/hvac\"\n",
        "\n",
        "# Remove existing directory if present\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(f\"‚ö†Ô∏è  Removing existing directory: {REPO_DIR}\")\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "\n",
        "# Clone repository\n",
        "print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
        "!git clone {REPO_URL} {REPO_DIR}\n",
        "\n",
        "# Change to repo directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print(f\"‚úÖ Repository cloned successfully\")\n",
        "print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Show directory contents\n",
        "print(\"\\nüìÅ Repository contents:\")\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "clone_repo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîê Step 5: Configure API Keys\n",
        "\n",
        "**CRITICAL:** Enter your API keys when prompted. These will be injected into `.env` file.\n",
        "\n",
        "You can get API keys from:\n",
        "- **Gemini:** https://makersuite.google.com/app/apikey\n",
        "- **OpenAI:** https://platform.openai.com/api-keys"
      ],
      "metadata": {
        "id": "step5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Attempt to load secrets using userdata.get\n",
        "print(\"üîê API Key Configuration\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Default to Colab secrets\n",
        "ai_provider = userdata.get('VITE_AI_PROVIDER') or \"gemini\"\n",
        "api_key = userdata.get('VITE_AI_API_KEY') or \"\"\n",
        "gemini_key = userdata.get('VITE_GEMINI_API_KEY') or \"\"\n",
        "\n",
        "# Fallback to manual input if keys are missing\n",
        "if not api_key:\n",
        "    print(\"\\n‚ö†Ô∏è  API key not found in Colab secrets. Falling back to manual input.\")\n",
        "    ai_provider = input(\"\\nSelect AI Provider (gemini/openai/anthropic) [gemini]: \").strip().lower() or \"gemini\"\n",
        "    if ai_provider == \"gemini\":\n",
        "        api_key = getpass(\"Enter your GEMINI API Key: \")\n",
        "        gemini_key = api_key\n",
        "    elif ai_provider == \"openai\":\n",
        "        api_key = getpass(\"Enter your OPENAI API Key: \")\n",
        "        gemini_key = \"\"\n",
        "    else:\n",
        "        api_key = getpass(\"Enter your API Key: \")\n",
        "        gemini_key = \"\"\n",
        "\n",
        "    # Optional: Gemini-specific key\n",
        "    if not gemini_key:\n",
        "        gemini_prompt = input(\"\\nAlso provide Gemini key? (y/n) [n]: \").strip().lower()\n",
        "        if gemini_prompt == 'y':\n",
        "            gemini_key = getpass(\"Enter your GEMINI API Key: \")\n",
        "\n",
        "# Generate .env file\n",
        "env_content = f\"\"\"# ============================================================================\n",
        "# AI Provider Configuration (Auto-generated by Colab Launcher)\n",
        "# ============================================================================\n",
        "\n",
        "# AI Provider Selection\n",
        "VITE_AI_PROVIDER={ai_provider}\n",
        "\n",
        "# AI API Key\n",
        "VITE_AI_API_KEY={api_key}\n",
        "\n",
        "# Provider-specific keys\n",
        "{f\"VITE_GEMINI_API_KEY={gemini_key}\" if gemini_key else \"# VITE_GEMINI_API_KEY=your_gemini_key_here\"}\n",
        "\n",
        "# Model Selection\n",
        "VITE_AI_MODEL={\"gemini-2.5-flash\" if ai_provider == \"gemini\" else \"gpt-4o\" if ai_provider == \"openai\" else \"claude-3-5-sonnet-20241022\"}\n",
        "\n",
        "# AI Generation Parameters\n",
        "VITE_AI_TEMPERATURE=0.2\n",
        "VITE_AI_MAX_TOKENS=4096\n",
        "\n",
        "# ============================================================================\n",
        "# Feature Flags\n",
        "# ============================================================================\n",
        "\n",
        "VITE_FEATURE_CACHE=true\n",
        "VITE_FEATURE_FILE_PROCESSING=true\n",
        "\n",
        "# ============================================================================\n",
        "# Rate Limiting\n",
        "# ============================================================================\n",
        "\n",
        "VITE_RATE_LIMIT_MAX_RETRIES=3\n",
        "VITE_RATE_LIMIT_DELAY_MS=1000\n",
        "VITE_RATE_LIMIT_EXPONENTIAL_BACKOFF=true\n",
        "\n",
        "# ============================================================================\n",
        "# File Processing\n",
        "# ============================================================================\n",
        "\n",
        "VITE_FILE_MAX_SIZE=10485760\n",
        "VITE_FILE_SUPPORTED_FORMATS=pdf,png,jpg,jpeg,dwg\n",
        "VITE_FILE_PDF_DPI=300\n",
        "\"\"\"\n",
        "\n",
        "# Write .env file\n",
        "env_path = \"/content/hvac/.env\"\n",
        "with open(env_path, \"w\") as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"\\n‚úÖ .env file created successfully\")\n",
        "print(f\"üìÑ Location: {env_path}\")\n",
        "print(\"\\n‚ö†Ô∏è  API keys are sensitive - never commit .env to version control!\")"
      ],
      "metadata": {
        "id": "configure_keys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 6: Install Dependencies\n",
        "\n",
        "Install npm dependencies for the project."
      ],
      "metadata": {
        "id": "step6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/hvac\n",
        "\n",
        "echo \"üì¶ Installing npm dependencies...\"\n",
        "echo \"‚è±Ô∏è  This may take 2-3 minutes...\"\n",
        "\n",
        "npm install\n",
        "\n",
        "echo \"‚úÖ Dependencies installed successfully\""
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Step 8: Launch Application\n",
        "\n",
        "**IMPORTANT:** This cell will start the application servers and create public URLs.\n",
        "\n",
        "The cell will:\n",
        "1. Run `start.py` to validate environment and start dev servers\n",
        "2. Create public tunnels for frontend (port 3000) and backend (port 4000)\n",
        "3. Print public URLs that you can access from any browser\n",
        "\n",
        "**Note:** The servers will keep running. To stop them, use Runtime ‚Üí Interrupt execution."
      ],
      "metadata": {
        "id": "step8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import requests\n",
        "import socket\n",
        "import sys\n",
        "import signal\n",
        "\n",
        "# Configuration\n",
        "FRONTEND_PORT = 3000\n",
        "BACKEND_PORT = 4000\n",
        "PROJECT_ROOT = '/content/hvac'\n",
        "\n",
        "# ANSI Colors for Logging\n",
        "class Colors:\n",
        "    HEADER = '\\033[95m'\n",
        "    BLUE = '\\033[94m'\n",
        "    CYAN = '\\033[96m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "\n",
        "print(f\"{Colors.HEADER}üöÄ Initializing HVAC AI Platform Universal Launcher...{Colors.ENDC}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Install Tunneling Tool\n",
        "print(\"üì¶ Ensuring localtunnel is installed...\")\n",
        "install_result = subprocess.run(['npm', 'install', '-g', 'localtunnel'], capture_output=True, text=True)\n",
        "if install_result.returncode == 0:\n",
        "    print(f\"{Colors.GREEN}‚úÖ localtunnel installed successfully{Colors.ENDC}\")\n",
        "else:\n",
        "    print(f\"{Colors.YELLOW}‚ö†Ô∏è  localtunnel install returned non-zero (might be installed). Continuing...{Colors.ENDC}\")\n",
        "\n",
        "# Ensure directory exists (fallback for local run)\n",
        "if not os.path.exists(PROJECT_ROOT):\n",
        "    # If not in Colab/Content, assume current directory\n",
        "    PROJECT_ROOT = os.getcwd()\n",
        "    print(f\"{Colors.YELLOW}‚ÑπÔ∏è  Running in local directory: {PROJECT_ROOT}{Colors.ENDC}\")\n",
        "\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "# 2. Cleanup Old Processes\n",
        "def kill_process_on_port(port):\n",
        "    try:\n",
        "        if sys.platform.startswith('linux'):\n",
        "            subprocess.run([\"fuser\", \"-k\", f\"{port}/tcp\"], capture_output=True)\n",
        "        # Add windows support if needed here, but usually this script is for Linux/Colab\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(\"üîç Pre-flight check: Cleaning ports...\")\n",
        "kill_process_on_port(FRONTEND_PORT)\n",
        "kill_process_on_port(BACKEND_PORT)\n",
        "\n",
        "# 3. Helper: Log Streamer (Real-time Verbose Logging)\n",
        "def stream_logs(process, prefix, color):\n",
        "    \"\"\"Reads stdout from a subprocess and prints it in real-time\"\"\"\n",
        "    try:\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            if line:\n",
        "                clean_line = line.strip()\n",
        "                if clean_line:\n",
        "                    print(f\"{color}[{prefix}] {clean_line}{Colors.ENDC}\")\n",
        "    except (ValueError, OSError):\n",
        "        pass\n",
        "\n",
        "# 4. Run Diagnostics (start.py)\n",
        "if os.path.exists('start.py'):\n",
        "    print(\"\\nü©∫ Running Platform Diagnostics...\")\n",
        "    diag_proc = subprocess.run([sys.executable, 'start.py', '--no-dev'], capture_output=True, text=True)\n",
        "    if diag_proc.returncode != 0:\n",
        "        print(f\"{Colors.FAIL}‚ùå Diagnostics Failed:{Colors.ENDC}\")\n",
        "        print(diag_proc.stdout)\n",
        "        # We continue anyway to attempt server launch\n",
        "    else:\n",
        "        print(f\"{Colors.GREEN}‚úÖ Environment Diagnostics Passed{Colors.ENDC}\")\n",
        "else:\n",
        "    print(f\"{Colors.YELLOW}‚ö†Ô∏è  start.py not found, skipping diagnostics...{Colors.ENDC}\")\n",
        "\n",
        "# 5. Launch Servers\n",
        "print(f\"\\n{Colors.BOLD}‚ö° Launching Services...{Colors.ENDC}\")\n",
        "\n",
        "# Start Frontend (Vite)\n",
        "frontend_proc = subprocess.Popen(\n",
        "    ['npm', 'run', 'dev'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    universal_newlines=True\n",
        ")\n",
        "\n",
        "# Start Backend (Node API)\n",
        "backend_proc = subprocess.Popen(\n",
        "    ['npm', 'run', 'dev:api'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    universal_newlines=True\n",
        ")\n",
        "\n",
        "# Start Log Threads\n",
        "t_front_logs = threading.Thread(target=stream_logs, args=(frontend_proc, \"Frontend\", Colors.CYAN))\n",
        "t_front_logs.daemon = True\n",
        "t_front_logs.start()\n",
        "\n",
        "t_back_logs = threading.Thread(target=stream_logs, args=(backend_proc, \"Backend \", Colors.BLUE))\n",
        "t_back_logs.daemon = True\n",
        "t_back_logs.start()\n",
        "\n",
        "# 6. Wait for Ports to Open\n",
        "def wait_for_port(port, timeout=60):\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < timeout:\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            if sock.connect_ex((\"localhost\", port)) == 0:\n",
        "                return True\n",
        "        time.sleep(1)\n",
        "    return False\n",
        "\n",
        "print(\"‚è≥ Waiting for servers to bind ports...\")\n",
        "if wait_for_port(FRONTEND_PORT) and wait_for_port(BACKEND_PORT):\n",
        "    print(f\"{Colors.GREEN}‚úÖ Servers are listening!{Colors.ENDC}\")\n",
        "else:\n",
        "    print(f\"{Colors.FAIL}‚ùå Timeout waiting for servers. Check logs above.{Colors.ENDC}\")\n",
        "\n",
        "# 7. Establish Tunnels\n",
        "tunnel_urls = {}\n",
        "\n",
        "def start_tunnel(port, name):\n",
        "    retries = 0\n",
        "    while retries < 5:\n",
        "        try:\n",
        "            proc = subprocess.Popen(\n",
        "                ['lt', '--port', str(port), '--local-host', 'localhost'],\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                text=True\n",
        "            )\n",
        "            for line in proc.stdout:\n",
        "                if 'your url is:' in line.lower():\n",
        "                    url = line.split('your url is:')[-1].strip()\n",
        "                    tunnel_urls[name] = url\n",
        "                    return proc\n",
        "            time.sleep(2)\n",
        "            retries += 1\n",
        "        except Exception:\n",
        "            retries += 1\n",
        "    return None\n",
        "\n",
        "print(\"üåê Negotiating Tunnels...\")\n",
        "start_tunnel(FRONTEND_PORT, 'Frontend')\n",
        "start_tunnel(BACKEND_PORT, 'Backend')\n",
        "\n",
        "# Get Local IP for convenience\n",
        "try:\n",
        "    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
        "    s.connect((\"8.8.8.8\", 80))\n",
        "    local_ip = s.getsockname()[0]\n",
        "    s.close()\n",
        "except:\n",
        "    local_ip = \"127.0.0.1\"\n",
        "\n",
        "# 8. Final Dashboard\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"{Colors.GREEN}{Colors.BOLD}üéâ HVAC AI PLATFORM ONLINE{Colors.ENDC}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"{Colors.CYAN}üåç PUBLIC ACCESS (Google Colab / Remote):{Colors.ENDC}\")\n",
        "print(f\"   Frontend: {Colors.BOLD}{tunnel_urls.get('Frontend', 'Waiting...')}{Colors.ENDC}\")\n",
        "print(f\"   Backend:  {Colors.BOLD}{tunnel_urls.get('Backend', 'Waiting...')}{Colors.ENDC}\")\n",
        "print(\"\")\n",
        "\n",
        "print(f\"{Colors.YELLOW}üè† LOCAL ACCESS (VS Code / Local Machine):{Colors.ENDC}\")\n",
        "print(f\"   Frontend: {Colors.BOLD}http://localhost:{FRONTEND_PORT}{Colors.ENDC}\")\n",
        "print(f\"   Backend:  {Colors.BOLD}http://localhost:{BACKEND_PORT}{Colors.ENDC}\")\n",
        "print(f\"   Network:  {Colors.BOLD}http://{local_ip}:{FRONTEND_PORT}{Colors.ENDC}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"{Colors.YELLOW}‚ÑπÔ∏è  NOTE: If using Public Access, the Tunnel Password is the IP below:{Colors.ENDC}\")\n",
        "try:\n",
        "    print(f\"   IP: {requests.get('https://api.ipify.org').text}\")\n",
        "except: pass\n",
        "print(\"=\" * 70)\n",
        "print(f\"{Colors.BOLD}üìù LIVE SERVER LOGS STREAMING BELOW:{Colors.ENDC}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# 9. Keep Alive & Monitor\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "        if frontend_proc.poll() is not None:\n",
        "            print(f\"{Colors.FAIL}‚ùå Frontend crashed!{Colors.ENDC}\")\n",
        "            break\n",
        "        if backend_proc.poll() is not None:\n",
        "            print(f\"{Colors.FAIL}‚ùå Backend crashed!{Colors.ENDC}\")\n",
        "            break\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Shutting down...\")\n",
        "    frontend_proc.terminate()\n",
        "    backend_proc.terminate()\n",
        "    kill_process_on_port(FRONTEND_PORT)\n",
        "    kill_process_on_port(BACKEND_PORT)"
      ],
      "metadata": {
        "id": "launch_app"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}