PS D:\AMD\secrets\hvac\extra\hvac> & D:/AMD/secrets/hvac/extra/hvac/.venv/Scripts/Activate.ps1
(.venv) PS D:\AMD\secrets\hvac\extra\hvac> & D:/AMD/secrets/hvac/extra/hvac/.venv/Scripts/python.exe d:/AMD/secrets/hvac/extra/hvac/start.py
HVAC - start orchestration script
Warning: Ollama not reachable at localhost:11434. Please ensure Ollama is running.
If you want this script to attempt starting Ollama, set OLLAMA_CMD environment variable.
Attempting to start Ollama with: C:\Users\AMD\AppData\Local\Programs\Ollama\ollama.EXE serve
Starting Ollama subprocess: C:\Users\AMD\AppData\Local\Programs\Ollama\ollama.EXE serve
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.916-06:00 level=INFO source=routes.go:1614 msg="server config" env="map[CUDA_VISIBLE_DEVICES: GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:C:\\Users\\AMD\\.ollama\\models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false OLLAMA_VULKAN:false ROCR_VISIBLE_DEVICES:]"
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.919-06:00 level=INFO source=images.go:499 msg="total blobs: 6"
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.919-06:00 level=INFO source=images.go:506 msg="total unused blobs removed: 0"
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.920-06:00 level=INFO source=routes.go:1667 msg="Listening on 127.0.0.1:11434 (version 0.14.1)"
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.922-06:00 level=INFO source=runner.go:67 msg="discovering available GPUs..."
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.956-06:00 level=INFO source=runner.go:106 msg="experimental Vulkan support disabled.  To enable, set OLLAMA_VULKAN=1"
[04:23:52] OLLAMA:ERR | time=2026-01-17T04:23:52.968-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 59296"
[04:23:53] OLLAMA:ERR | time=2026-01-17T04:23:53.323-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 59305"
[04:23:53] OLLAMA:ERR | time=2026-01-17T04:23:53.662-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 59312"
[04:23:53] OLLAMA:ERR | time=2026-01-17T04:23:53.786-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 59319"
[04:23:53] OLLAMA:ERR | time=2026-01-17T04:23:53.786-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 59320"
[04:23:54] OLLAMA:ERR | time=2026-01-17T04:23:54.163-06:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 filter_id="" library=CUDA compute=6.1 name=CUDA0 description="NVIDIA GeForce GTX 1070" libdirs=ollama,cuda_v12 driver=13.0 pci_id=0000:26:00.0 type=discrete total="8.0 GiB" available="7.0 GiB"
[04:23:54] OLLAMA:ERR | time=2026-01-17T04:23:54.163-06:00 level=INFO source=routes.go:1708 msg="entering low vram mode" "total vram"="8.0 GiB" threshold="20.0 GiB"
[04:23:54] OLLAMA | [GIN] 2026/01/17 - 04:23:54 | 200 |      1.5816ms |       127.0.0.1 | GET      "/v1/models"
Ollama is up
Starting backend (FastAPI)...
Waiting for backend to be healthy... (timeout 60s)
[04:23:55] BACKEND:ERR | INFO:     Will watch for changes in these directories: ['D:\\AMD\\secrets\\hvac\\extra\\hvac']
[04:23:55] BACKEND:ERR | INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
[04:23:55] BACKEND:ERR | INFO:     Started reloader process [24708] using StatReload
[04:23:57] BACKEND:ERR | INFO:     Started server process [23240]
[04:23:57] BACKEND:ERR | INFO:     Waiting for application startup.
[04:23:57] BACKEND:ERR | INFO:     Application startup complete.
[04:24:00] BACKEND | INFO:     127.0.0.1:59350 - "GET /api/catalog HTTP/1.1" 200 OK
Backend healthy
Starting frontend (Vite)...
Waiting for frontend dev server... (timeout 60s)
[04:24:00] FRONTEND | 
[04:24:00] FRONTEND | > hvac-ai@1.0.0 dev
[04:24:00] FRONTEND | > vite --port 3000
[04:24:00] FRONTEND |
[04:24:01] FRONTEND | 
[04:24:01] FRONTEND |   VITE v6.4.1  ready in 439 ms
[04:24:01] FRONTEND |
[04:24:01] FRONTEND |   ➜  Local:   http://localhost:3000/
[04:24:01] FRONTEND |   ➜  Network: http://172.23.80.1:3000/
[04:24:01] FRONTEND |   ➜  Network: http://192.168.0.13:3000/
[04:24:01] FRONTEND |   ➜  press h + enter to show help
Frontend dev server ready
Frontend URL: http://localhost:3000/
All services started successfully.
All services started successfully. Press Ctrl-C to stop everything.
Open the frontend in your browser: http://localhost:3000/
[04:24:08] OLLAMA | [GIN] 2026/01/17 - 04:24:08 | 200 |      3.8126ms |       127.0.0.1 | GET      "/v1/models"
[04:24:08] BACKEND | 2026-01-17 04:24:08,546 - httpx - [INFO] - HTTP Request: GET http://localhost:11434/v1/models "HTTP/1.1 200 OK"
[04:24:08] BACKEND | INFO:     127.0.0.1:64077 - "GET /api/model HTTP/1.1" 200 OK
[04:24:27] BACKEND | INFO:     127.0.0.1:62832 - "OPTIONS /api/upload HTTP/1.1" 200 OK
[04:24:27] BACKEND | 2026-01-17 04:24:27,080 - backend.utils - [INFO] - [req-5118dead6ebb] Starting: upload_pdf
[04:24:27] BACKEND | 2026-01-17 04:24:27,086 - backend.utils - [INFO] - [req-5118dead6ebb] Saved PDF: backend/uploads\up-30d3b375.pdf
[04:24:29] BACKEND:ERR | INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest
[04:24:29] BACKEND:ERR | INFO:__main__:PDF metadata extracted: 1 pages
[04:24:29] BACKEND:ERR | INFO:mcp.server.lowlevel.server:Processing request of type ListToolsRequest
[04:24:29] BACKEND:ERR | INFO:mcp.server.lowlevel.server:Processing request of type CallToolRequest
[04:24:30] BACKEND:ERR | INFO:__main__:Rendered page 1: 5184x3456px (zoom=2.0x)
[04:24:30] BACKEND | 2026-01-17 04:24:30,389 - backend.utils - [INFO] - [req-5118dead6ebb] Completed: upload_pdf in 3.31s
[04:24:30] BACKEND | INFO:     127.0.0.1:62832 - "POST /api/upload HTTP/1.1" 200 OK
[04:24:34] BACKEND | INFO:     127.0.0.1:62832 - "OPTIONS /api/analyze HTTP/1.1" 200 OK
[04:24:34] BACKEND | 2026-01-17 04:24:34,507 - backend.utils - [INFO] - [req-d00e9cf54b1a] Starting: analyze_document
[04:24:34] BACKEND | 2026-01-17 04:24:34,507 - backend.utils - [INFO] - [req-d00e9cf54b1a] Starting pipeline with qwen2.5vl
[04:24:34] BACKEND | 2026-01-17 04:24:34,512 - backend.utils - [INFO] - [req-d00e9cf54b1a] Starting: extract_page_1
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.384-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --port 61147"
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.821-06:00 level=INFO source=cpu_windows.go:148 msg=packages count=1
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.821-06:00 level=INFO source=cpu_windows.go:195 msg="" package=0 cores=8 efficiency=0 threads=16
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.935-06:00 level=INFO source=server.go:429 msg="starting runner" cmd="C:\\Users\\AMD\\AppData\\Local\\Programs\\Ollama\\ollama.exe runner --ollama-engine --model C:\\Users\\AMD\\.ollama\\models\\blobs\\sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025 --port 61155"
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.941-06:00 level=INFO source=sched.go:452 msg="system memory" total="15.9 GiB" free="7.8 GiB" free_swap="36.4 GiB"
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.941-06:00 level=INFO source=sched.go:459 msg="gpu memory" id=GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 library=CUDA available="6.6 GiB" free="7.0 GiB" minimum="457.0 MiB" overhead="0 B"
[04:24:35] OLLAMA:ERR | time=2026-01-17T04:24:35.941-06:00 level=INFO source=server.go:755 msg="loading model" "model layers"=29 requested=-1
[04:24:36] OLLAMA:ERR | time=2026-01-17T04:24:36.003-06:00 level=INFO source=runner.go:1405 msg="starting ollama engine"
[04:24:36] OLLAMA:ERR | time=2026-01-17T04:24:36.004-06:00 level=INFO source=runner.go:1440 msg="Server listening on 127.0.0.1:61155"
[04:24:36] OLLAMA:ERR | time=2026-01-17T04:24:36.009-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:29[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:29(0..28)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:36] OLLAMA:ERR | time=2026-01-17T04:24:36.051-06:00 level=INFO source=ggml.go:136 msg="" architecture=qwen25vl file_type=Q4_K_M name="" description="" num_tensors=858 num_key_values=36
[04:24:36] OLLAMA:ERR | load_backend: loaded CPU backend from C:\Users\AMD\AppData\Local\Programs\Ollama\lib\ollama\ggml-cpu-haswell.dll
[04:24:36] OLLAMA:ERR | ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
[04:24:36] OLLAMA:ERR | ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
[04:24:36] OLLAMA:ERR | ggml_cuda_init: found 1 CUDA devices:
[04:24:36] OLLAMA:ERR |   Device 0: NVIDIA GeForce GTX 1070, compute capability 6.1, VMM: yes, ID: GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61
[04:24:36] OLLAMA:ERR | load_backend: loaded CUDA backend from C:\Users\AMD\AppData\Local\Programs\Ollama\lib\ollama\cuda_v12\ggml-cuda.dll
[04:24:36] OLLAMA:ERR | time=2026-01-17T04:24:36.236-06:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,520,600,610,700,750,800,860,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(clang)
[04:24:37] OLLAMA:ERR | time=2026-01-17T04:24:37.395-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"        
[04:24:38] OLLAMA:ERR | time=2026-01-17T04:24:38.237-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:28[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:28(0..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:39] OLLAMA:ERR | time=2026-01-17T04:24:39.045-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:27[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:27(1..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:39] OLLAMA:ERR | time=2026-01-17T04:24:39.858-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:26[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:26(2..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:40] OLLAMA:ERR | time=2026-01-17T04:24:40.697-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:25[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:25(3..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:41] OLLAMA:ERR | time=2026-01-17T04:24:41.433-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:24[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:24(4..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:42] OLLAMA:ERR | time=2026-01-17T04:24:42.183-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:23[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:23(5..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:42] OLLAMA:ERR | time=2026-01-17T04:24:42.944-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:22[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:22(6..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:43] OLLAMA:ERR | time=2026-01-17T04:24:43.687-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:21[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:21(7..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:44] OLLAMA:ERR | time=2026-01-17T04:24:44.607-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:20[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:20(8..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:45] OLLAMA:ERR | time=2026-01-17T04:24:45.598-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:19(9..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:46] OLLAMA:ERR | time=2026-01-17T04:24:46.465-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:18[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:18(10..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:47] OLLAMA:ERR | time=2026-01-17T04:24:47.174-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:17[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:17(11..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:47] OLLAMA:ERR | time=2026-01-17T04:24:47.897-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:16[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:16(12..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:48] OLLAMA:ERR | time=2026-01-17T04:24:48.561-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:15[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:15(13..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:49] OLLAMA:ERR | time=2026-01-17T04:24:49.238-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:14[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:14(14..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:50] OLLAMA:ERR | time=2026-01-17T04:24:50.012-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:13[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:13(15..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:50] OLLAMA:ERR | time=2026-01-17T04:24:50.727-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:12[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:12(16..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:51] OLLAMA:ERR | time=2026-01-17T04:24:51.437-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:11[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:11(17..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:52] OLLAMA:ERR | time=2026-01-17T04:24:52.152-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:10[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:10(18..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:52] OLLAMA:ERR | time=2026-01-17T04:24:52.877-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:9[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:9(19..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:53] OLLAMA:ERR | time=2026-01-17T04:24:53.548-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:8[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:8(20..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:54] OLLAMA:ERR | time=2026-01-17T04:24:54.223-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:7[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:7(21..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:54] OLLAMA:ERR | time=2026-01-17T04:24:54.931-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:6[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:6(22..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:55] OLLAMA:ERR | time=2026-01-17T04:24:55.620-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:5[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:5(23..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:56] OLLAMA:ERR | time=2026-01-17T04:24:56.318-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:4[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:4(24..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:57] OLLAMA:ERR | time=2026-01-17T04:24:57.016-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:3[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:3(25..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:57] OLLAMA:ERR | time=2026-01-17T04:24:57.726-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:2[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:2(26..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:58] OLLAMA:ERR | time=2026-01-17T04:24:58.409-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:1[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:1(27..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:24:59] OLLAMA:ERR | time=2026-01-17T04:24:59.123-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"        
[04:24:59] OLLAMA:ERR | time=2026-01-17T04:24:59.845-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"      
[04:25:00] OLLAMA:ERR | time=2026-01-17T04:25:00.872-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:28[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:28(0..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:04] OLLAMA:ERR | time=2026-01-17T04:25:04.616-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:27[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:27(1..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:07] OLLAMA:ERR | time=2026-01-17T04:25:07.312-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:26[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:26(2..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:10] OLLAMA:ERR | time=2026-01-17T04:25:10.157-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:25[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:25(3..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:12] OLLAMA:ERR | time=2026-01-17T04:25:12.913-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:24[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:24(4..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:15] OLLAMA:ERR | time=2026-01-17T04:25:15.462-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:23[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:23(5..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:17] OLLAMA:ERR | time=2026-01-17T04:25:17.626-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:22[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:22(6..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:20] OLLAMA:ERR | time=2026-01-17T04:25:20.148-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:21[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:21(7..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:23] OLLAMA:ERR | time=2026-01-17T04:25:23.148-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:20[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:20(8..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:26] OLLAMA:ERR | time=2026-01-17T04:25:26.302-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:19(9..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:28] OLLAMA:ERR | time=2026-01-17T04:25:28.768-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:18[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:18(10..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:30] OLLAMA:ERR | time=2026-01-17T04:25:30.947-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:17[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:17(11..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:33] OLLAMA:ERR | time=2026-01-17T04:25:33.092-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:16[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:16(12..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:35] OLLAMA:ERR | time=2026-01-17T04:25:35.027-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:15[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:15(13..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:37] OLLAMA:ERR | time=2026-01-17T04:25:37.279-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:14[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:14(14..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:39] OLLAMA:ERR | time=2026-01-17T04:25:39.161-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:13[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:13(15..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:40] OLLAMA:ERR | time=2026-01-17T04:25:40.938-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:12[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:12(16..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:42] OLLAMA:ERR | time=2026-01-17T04:25:42.803-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:11[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:11(17..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:44] OLLAMA:ERR | time=2026-01-17T04:25:44.691-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:10[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:10(18..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:46] OLLAMA:ERR | time=2026-01-17T04:25:46.341-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:9[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:9(19..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:48] OLLAMA:ERR | time=2026-01-17T04:25:48.153-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:8[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:8(20..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:49] OLLAMA:ERR | time=2026-01-17T04:25:49.718-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:7[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:7(21..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:51] OLLAMA:ERR | time=2026-01-17T04:25:51.219-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:6[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:6(22..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:52] OLLAMA:ERR | time=2026-01-17T04:25:52.670-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:5[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:5(23..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:54] OLLAMA:ERR | time=2026-01-17T04:25:54.110-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:4[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:4(24..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:55] OLLAMA:ERR | time=2026-01-17T04:25:55.523-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:3[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:3(25..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:56] OLLAMA:ERR | time=2026-01-17T04:25:56.948-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:2[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:2(26..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:58] OLLAMA:ERR | time=2026-01-17T04:25:58.259-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:1[ID:GPU-ceb7970b-f836-81d2-c126-25b8b7e0da61 Layers:1(27..27)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
[04:25:59] OLLAMA:ERR | time=2026-01-17T04:25:59.626-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"      
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.118-06:00 level=INFO source=runner.go:1278 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:Disabled KvSize:4096 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"     
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=device.go:245 msg="model weights" device=CPU size="5.6 GiB"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=device.go:256 msg="kv cache" device=CPU size="224.0 MiB"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=device.go:267 msg="compute graph" device=CPU size="6.7 GiB"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=device.go:272 msg="total memory" size="12.5 GiB"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=ggml.go:482 msg="offloading 0 repeating layers to GPU"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=ggml.go:486 msg="offloading output layer to CPU"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.120-06:00 level=INFO source=ggml.go:494 msg="offloaded 0/29 layers to GPU"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.121-06:00 level=INFO source=sched.go:526 msg="loaded runners" count=1
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.121-06:00 level=INFO source=server.go:1347 msg="waiting for llama runner to start responding"
[04:26:01] OLLAMA:ERR | time=2026-01-17T04:26:01.124-06:00 level=INFO source=server.go:1381 msg="waiting for server to become available" status="llm server loading model"
[04:26:07] OLLAMA:ERR | time=2026-01-17T04:26:07.912-06:00 level=INFO source=server.go:1385 msg="llama runner started in 91.97 seconds"