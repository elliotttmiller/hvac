# HVAC Analysis Backend Configuration
# Copy this file to .env and adjust values as needed

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama
MODEL_NAME=qwen2.5vl

# Processing Limits
MAX_PAGES_DEFAULT=20
MAX_FILE_SIZE_MB=50
# Global timeout in seconds (Default 120s is too short for 20-page local inference)
# 300s = 5 minutes. Essential for GTX 1070.
API_TIMEOUT=300

# Inference Parameters
EXTRACTION_TEMPERATURE=0.0
REASONING_TEMPERATURE=0.1
# Bumped to 2000 to prevent cutting off dense blueprint text
EXTRACTION_MAX_TOKENS=2000
CONTEXT_WINDOW_MAX_TOKENS=28000

# PDF Rendering
# Zoom factor for PDF to image conversion (1.0-4.0)
# 2.0 = Balanced (Good for GTX 1070 8GB VRAM)
# 3.0 = High Detail (Use only if text is blurry)
PDF_ZOOM_FACTOR=2.0

# Retry Configuration
MAX_RETRIES=2
RETRY_INITIAL_DELAY=2.0
RETRY_BACKOFF_FACTOR=2.0

# Paths
UPLOAD_DIR=backend/uploads
DATA_DIR=backend/data

# CORS (comma-separated list)
CORS_ORIGINS=*

# Logging
LOG_LEVEL=INFO