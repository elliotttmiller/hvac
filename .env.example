# HVAC Analysis Backend Configuration
# Copy this file to .env and adjust values as needed

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# AI Provider Configuration
# Choose provider: "ollama" or "gemini"
AI_PROVIDER=ollama

# Ollama Configuration (when AI_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama
MODEL_NAME=qwen2.5vl

# Google Gemini Configuration (when AI_PROVIDER=gemini)
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here
# Choose model: "gemini-2.0-flash-exp" (Gemini 2.5 Flash) or "gemini-2.0-flash-thinking-exp-01-21" (Gemini 3 Flash Preview)
GEMINI_MODEL=gemini-2.0-flash-exp

# Processing Limits
MAX_PAGES_DEFAULT=20
MAX_FILE_SIZE_MB=50
# Global timeout in seconds (Default 120s is too short for 20-page local inference)
# 300s = 5 minutes. Essential for GTX 1070.
API_TIMEOUT=300

# Inference Parameters
EXTRACTION_TEMPERATURE=0.0
REASONING_TEMPERATURE=0.1
# Bumped to 2000 to prevent cutting off dense blueprint text
EXTRACTION_MAX_TOKENS=2000
CONTEXT_WINDOW_MAX_TOKENS=28000

# PDF Rendering
# Zoom factor for PDF to image conversion (1.0-4.0)
# 2.0 = Balanced (Good for GTX 1070 8GB VRAM)
# 3.0 = High Detail (Use only if text is blurry)
PDF_ZOOM_FACTOR=2.0

# Retry Configuration
MAX_RETRIES=2
RETRY_INITIAL_DELAY=2.0
RETRY_BACKOFF_FACTOR=2.0

# Paths
UPLOAD_DIR=backend/uploads
DATA_DIR=backend/data

# CORS (comma-separated list)
CORS_ORIGINS=*

# Logging
LOG_LEVEL=INFO